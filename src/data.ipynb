{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ebbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0e62ac",
   "metadata": {},
   "source": [
    "Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e353a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKERS = [\"AAPL\", \"MSFT\", \"AMZN\", \"GOOGL\", \"META\"]\n",
    "START_DATE = \"2015-01-01\"\n",
    "END_DATE = \"2024-01-01\"\n",
    "RAW_DIR=\"../data/raw\"\n",
    "os.makedirs(RAW_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b2c595c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading AAPL from Stooq (aapl.us)...\n",
      "Saved AAPL: 2264 rows\n",
      "Downloading MSFT from Stooq (msft.us)...\n",
      "Saved MSFT: 2264 rows\n",
      "Downloading AMZN from Stooq (amzn.us)...\n",
      "Saved AMZN: 2264 rows\n",
      "Downloading GOOGL from Stooq (googl.us)...\n",
      "Saved GOOGL: 2264 rows\n",
      "Downloading META from Stooq (meta.us)...\n",
      "Saved META: 2264 rows\n"
     ]
    }
   ],
   "source": [
    "def download_data(tickers, start, end, out_dir):\n",
    "    for t in tickers:\n",
    "        stooq_symbol = t.lower() + \".us\"\n",
    "        print(f\"Downloading {t} from Stooq ({stooq_symbol})...\")\n",
    "\n",
    "        url = f\"https://stooq.com/q/d/l/?s={stooq_symbol}&i=d\"\n",
    "        df = pd.read_csv(url)\n",
    "\n",
    "        if df is None or df.empty:\n",
    "            print(f\"ERROR: No data returned for {t}\")\n",
    "            continue\n",
    "\n",
    "        df = df.dropna()\n",
    "        df = df.sort_values(\"Date\")\n",
    "\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "        mask = (df[\"Date\"] >= pd.to_datetime(start)) & (df[\"Date\"] <= pd.to_datetime(end))\n",
    "        df = df.loc[mask]\n",
    "\n",
    "        out_path = f\"{out_dir}/{t}.csv\"\n",
    "        df.to_csv(out_path, index=False)\n",
    "\n",
    "        print(f\"Saved {t}: {df.shape[0]} rows\")\n",
    "\n",
    "download_data(TICKERS, START_DATE, END_DATE, RAW_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b61190ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_indicators(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # Daily log returns\n",
    "    df[\"ret\"] = np.log(df[\"Close\"] / df[\"Close\"].shift(1))\n",
    "\n",
    "    # Rolling volatility (10-day and 20-day)\n",
    "    df[\"vol_10\"] = df[\"ret\"].rolling(10).std()\n",
    "    df[\"vol_20\"] = df[\"ret\"].rolling(20).std()\n",
    "\n",
    "    # RSI(14)\n",
    "    delta = df[\"Close\"].diff()\n",
    "    gain = delta.clip(lower=0).rolling(14).mean()\n",
    "    loss = (-delta.clip(upper=0)).rolling(14).mean()\n",
    "    rs = gain / (loss + 1e-9)\n",
    "    df[\"rsi_14\"] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # 10-day momentum (rate of change)\n",
    "    df[\"mom_10\"] = df[\"Close\"] / df[\"Close\"].shift(10) - 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71f481c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_all(tickers, raw_dir):\n",
    "    dfs = {}\n",
    "    for t in tickers:\n",
    "        path = os.path.join(raw_dir, f\"{t}.csv\")\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Missing raw file for {t}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(path)\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "        df = df.set_index(\"Date\")\n",
    "\n",
    "        df = compute_indicators(df)\n",
    "        dfs[t] = df\n",
    "\n",
    "    # Merge\n",
    "    common_index = None\n",
    "    for t, df in dfs.items():\n",
    "        common_index = df.index if common_index is None else common_index.intersection(df.index)\n",
    "    for t in dfs:\n",
    "        df = dfs[t].loc[common_index].copy()\n",
    "        df = df.dropna()\n",
    "        dfs[t] = df\n",
    "    common_index = None\n",
    "    for t, df in dfs.items():\n",
    "        common_index = df.index if common_index is None else common_index.intersection(df.index)\n",
    "    for t in dfs:\n",
    "        dfs[t] = dfs[t].loc[common_index].copy()\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cb8555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing indicators and returns...\n",
      "Saved processed features for AAPL\n",
      "Saved processed features for MSFT\n",
      "Saved processed features for AMZN\n",
      "Saved processed features for GOOGL\n",
      "Saved processed features for META\n",
      "Saved returns_matrix.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>META</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-02-02</th>\n",
       "      <td>0.012251</td>\n",
       "      <td>0.021443</td>\n",
       "      <td>0.027651</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>-0.012194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-03</th>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.007717</td>\n",
       "      <td>-0.002527</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.005453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04</th>\n",
       "      <td>0.007516</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>-0.013593</td>\n",
       "      <td>0.003046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-05</th>\n",
       "      <td>0.007303</td>\n",
       "      <td>0.014466</td>\n",
       "      <td>0.024749</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>-0.000264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-06</th>\n",
       "      <td>-0.008714</td>\n",
       "      <td>-0.000908</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.007620</td>\n",
       "      <td>-0.015192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AAPL      MSFT      AMZN     GOOGL      META\n",
       "Date                                                        \n",
       "2015-02-02  0.012251  0.021443  0.027651 -0.010001 -0.012194\n",
       "2015-02-03  0.000189  0.007717 -0.002527  0.002065  0.005453\n",
       "2015-02-04  0.007516  0.005750  0.003295 -0.013593  0.003046\n",
       "2015-02-05  0.007303  0.014466  0.024749  0.007060 -0.000264\n",
       "2015-02-06 -0.008714 -0.000908  0.001043  0.007620 -0.015192"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROCESSED_DIR = \"../data/processed\"\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Computing indicators and returns...\")\n",
    "dfs = load_and_process_all(TICKERS, RAW_DIR)\n",
    "\n",
    "for t, df in dfs.items():\n",
    "    df.reset_index().to_csv(f\"{PROCESSED_DIR}/{t}.csv\", index=False)\n",
    "    print(f\"Saved processed features for {t}\")\n",
    "\n",
    "returns_df = pd.DataFrame(\n",
    "    {t: df[\"ret\"] for t, df in dfs.items()},\n",
    "    index=next(iter(dfs.values())).index\n",
    ")\n",
    "returns_df.reset_index().to_csv(f\"{PROCESSED_DIR}/returns_matrix.csv\", index=False)\n",
    "print(\"Saved returns matrix\")\n",
    "\n",
    "returns_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rebalance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
